{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open('../data/train.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = json.load(open('../data/test.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV for `test` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y_test(data):\n",
    "    X = []\n",
    "    for line in data:\n",
    "        sub_list = [line['id']]\n",
    "        sub_list.append(line['inc_angle'])\n",
    "        sub_list.extend(line['band_1'])\n",
    "        sub_list.extend(line['band_2'])\n",
    "        X.append(sub_list)\n",
    "    return np.array(X)\n",
    "\n",
    "def csv_test():\n",
    "    data=test_data\n",
    "    X = create_X_y_test(test_data)    \n",
    "    band_1 = ['b1_' + str(x) for x in range(len(data[0]['band_1']))]\n",
    "    band_2 = ['b2_' + str(x) for x in range(len(data[0]['band_2']))]\n",
    "    column_names = ['id'] + ['inc_angle'] + band_1 + band_2\n",
    "    df = DataFrame(data=X, columns=column_names)\n",
    "\n",
    "    df.to_csv(\"test_data.csv\", index=False)\n",
    "    \n",
    "csv_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV for `train` data with `inc_angle` feature removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y(data):\n",
    "    X = []\n",
    "    for line in data:\n",
    "        sub_list = [line['id']]\n",
    "        sub_list.append(line['inc_angle'])\n",
    "        sub_list.extend(line['band_1'])\n",
    "        sub_list.extend(line['band_2'])\n",
    "        sub_list.append(line['is_iceberg'])\n",
    "        X.append(sub_list)\n",
    "    return np.array(X)\n",
    "\n",
    "def csv_train_inc_feature_removed():\n",
    "    data=train_data\n",
    "    X = create_X_y(train_data)    \n",
    "    band_1 = ['b1_' + str(x) for x in range(len(data[0]['band_1']))]\n",
    "    band_2 = ['b2_' + str(x) for x in range(len(data[0]['band_2']))]\n",
    "    column_names = ['id'] + ['inc_angle'] + band_1 + band_2 + ['is_iceberg']\n",
    "    df = DataFrame(data=X, columns=column_names)\n",
    "\n",
    "    del df['inc_angle']\n",
    "\n",
    "    df.to_csv(\"data_processed_angle_removed.csv\", index=False)\n",
    "    \n",
    "csv_train_inc_feature_removed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV for `train` data removing any row with missing `inc_angle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_X_y_ignore_missing_inc_rows(data):\n",
    "    X = []\n",
    "    for line in data:\n",
    "        if line['inc_angle'] == 'na':\n",
    "            continue\n",
    "        sub_list = [line['id']]\n",
    "        sub_list.append(line['inc_angle'])\n",
    "        sub_list.extend(line['band_1'])\n",
    "        sub_list.extend(line['band_2'])\n",
    "        sub_list.append(line['is_iceberg'])\n",
    "        X.append(sub_list)\n",
    "    return np.array(X)\n",
    "\n",
    "def csv_train_inc_angle_missing_rows_removed():\n",
    "    data=train_data\n",
    "    X = create_X_y_ignore_missing_inc_rows(train_data)\n",
    "    band_1 = ['b1_' + str(x) for x in range(len(data[0]['band_1']))]\n",
    "    band_2 = ['b2_' + str(x) for x in range(len(data[0]['band_2']))]\n",
    "    column_names = ['id'] + ['inc_angle'] + band_1 + band_2 + ['is_iceberg']\n",
    "    df = DataFrame(data=X, columns=column_names)\n",
    "    df.to_csv(\"data_processed_rows_eliminated.csv\", index=False)    \n",
    "    \n",
    "csv_train_inc_angle_missing_rows_removed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create CSV for `train` data by merging `band_1` and `band_2` and remove rows with missing `inc_angle`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def create_X_y_merge_bands_ignore_missing_inc_rows(data):\n",
    "    X = []\n",
    "    for line in data:\n",
    "        if line['inc_angle'] == 'na':\n",
    "            continue\n",
    "        band = [math.log(math.exp(float(elem[0]))+math.exp(float(elem[1]))) for elem in zip(line['band_1'], line['band_2'])]\n",
    "        sub_list = [line['id']]\n",
    "        sub_list.append(line['inc_angle'])\n",
    "        sub_list.extend(band)\n",
    "        sub_list.append(line['is_iceberg'])\n",
    "        X.append(sub_list)\n",
    "    return np.array(X)\n",
    "\n",
    "def csv_train_bands_merged_inc_angle_missing_rows_removed():    \n",
    "    data = train_data\n",
    "    X = create_X_y_merge_bands_ignore_missing_inc_rows(data)\n",
    "    band = ['b' + str(x) for x in range(len(data[0]['band_1']))]\n",
    "    column_names = ['id'] + ['inc_angle'] + band + ['is_iceberg']\n",
    "    df = DataFrame(data=X, columns=column_names)\n",
    "    df.to_csv(\"data_processed_bands_combined.csv\", index=False)\n",
    "    \n",
    "csv_train_bands_merged_inc_angle_missing_rows_removed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PCA for `train` data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def read_train_pca_csv(infile):\n",
    "    # Skip the header\n",
    "    header = infile.readline().rstrip().split(',')\n",
    "    x_angle = []\n",
    "    x_id = []\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in infile:\n",
    "        line = line.rstrip().split(',')\n",
    "        # Skip the ID\n",
    "        x_id.append(line[0])\n",
    "        x_angle.append(float(line[1]))\n",
    "        X.append([float(x) for x in line[2:-1]])\n",
    "        y.append(int(line[-1]))\n",
    "    return np.array(x_id), np.array(x_angle), np.array(X), np.array(y)\n",
    "\n",
    "def read_test(infile):\n",
    "    # Skip the header\n",
    "    header = infile.readline().rstrip().split(',')\n",
    "    x_angle = []\n",
    "    x_id = []\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in infile:\n",
    "        line = line.rstrip().split(',')\n",
    "        # Skip the ID\n",
    "        x_id.append(line[0])\n",
    "        x_angle.append(float(line[1]))\n",
    "        X.append([float(x) for x in line[2:]])\n",
    "    return np.array(x_id), np.array(x_angle), np.array(X)\n",
    "\n",
    "def fit_pca(infile,outfile,num_basis):\n",
    "#     parser = ArgumentParser(description=\"PCA dimension reduction\")\n",
    "#     parser.add_argument('-i', '--infile', type=argparse.FileType('r'), \n",
    "#             help=\"csv file format with label in the last column\", default=sys.stdin)\n",
    "#     parser.add_argument('-t', '--testfile', type=argparse.FileType('r'), \n",
    "#             help=\"csv file format without label in the last column\", default=sys.stdin)\n",
    "#     parser.add_argument('-o', '--outfile', type=str, help=\"output file name\")\n",
    "#     parser.add_argument('-n', '--num_basis', type=int, default=100, help=\"number of basis vectors to use for dimension reduction\")\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "    #####################################################################\n",
    "    # Prepare X and y from the input txt file\n",
    "    f = open(infile, 'r+')\n",
    "    train_id, train_angle, X_train, y_train = read_train_pca_csv(f)\n",
    "\n",
    "    train_id = train_id.reshape((train_id.shape[0],1))\n",
    "    train_angle = train_angle.reshape((train_angle.shape[0],1))\n",
    "    y_train = y_train.reshape((y_train.shape[0],1))\n",
    "\n",
    "    # project the feature space up n dimensions\n",
    "    pca = PCA(num_basis)\n",
    "    pca.fit(X_train)\n",
    "\n",
    "    X_train = pca.transform(X_train)\n",
    "\n",
    "    band = ['b' + str(i) for i in range(X_train.shape[1])]\n",
    "    \n",
    "    # Dataset without angle\n",
    "    # data_wo_angle = np.hstack((x_id, X, y))\n",
    "    # column_names = ['id'] + band + ['is_iceberg']\n",
    "    # df_wo = pd.DataFrame(data_wo_angle, columns=column_names)\n",
    "    # filename = \"data/data_processed_pca\" + str(n) + \"wo_angle.csv\"\n",
    "    # df_wo.to_csv(filename, index=False)\n",
    "\n",
    "    # Dataset with angle (angle + PCA eigenvectors)\n",
    "    data_w_angle = np.hstack((train_id, train_angle, X_train, y_train))\n",
    "    column_names = ['id'] + ['inc_angle'] + band + ['is_iceberg']\n",
    "    df_w = pd.DataFrame(data_w_angle, columns=column_names)\n",
    "    filename = outfile + '_' + str(num_basis) + \".csv\"\n",
    "    df_w.to_csv(filename, index=False)\n",
    "\n",
    "    # Testset\n",
    "#     print(\"Transforming test set\")\n",
    "#     X_test = pca.transform(X_test)\n",
    "\n",
    "#     data_w_angle = np.hstack((test_id, test_angle, X_test))\n",
    "#     column_names = ['id'] + ['inc_angle'] + band \n",
    "#     df_w = pd.DataFrame(data_w_angle, columns=column_names)\n",
    "#     filename = \"data/test_\" + args.outfile + str(n) + \".csv\"\n",
    "#     df_w.to_csv(filename, index=False)\n",
    "\n",
    "fit_pca('data_processed_rows_eliminated.csv','pca_data_processed',50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELS — k-NN, NN, SVM, RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.svm\n",
    "import sklearn.ensemble\n",
    "import sklearn.neighbors\n",
    "import sklearn.neural_network\n",
    "import sklearn.model_selection\n",
    "import sklearn.metrics\n",
    "\n",
    "def support_vector_machine(X_train, y_train, X_test, C, kernel, degree, gamma):\n",
    "    if C==None:\n",
    "        C=1.0\n",
    "    if kernel==None:\n",
    "        kernel=\"rbf\"\n",
    "    if degree==None:\n",
    "        degree=3\n",
    "    if gamma==None:\n",
    "        gamma='auto'\n",
    "    clf = sklearn.svm.SVC(C=C, kernel=kernel, degree=degree, gamma=gamma)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "def random_forest(X_train, y_train, X_test, n, criterion, minss):\n",
    "    if n==None:\n",
    "        n=10\n",
    "    if criterion==None:\n",
    "        criterion=\"gini\"\n",
    "    if minss==None:\n",
    "        minss=2\n",
    "    clf = sklearn.ensemble.RandomForestClassifier(n_estimators=n, criterion=criterion, min_samples_split=minss)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test)\n",
    "\n",
    "def k_nearest_neighbor(X_train, y_train, X_test, n, weights):\n",
    "    if n==None:\n",
    "        n=5\n",
    "    if weights==None:\n",
    "        weights=\"uniform\"\n",
    "    neigh = sklearn.neighbors.KNeighborsClassifier(n_neighbors=n, weights=weights)\n",
    "    neigh.fit(X_train, y_train)\n",
    "    return neigh.predict(X_test)\n",
    "    \n",
    "def neural_network(X_train, y_train, X_test, hls, activation, solver, alpha): \n",
    "    if hls==None:\n",
    "        hls=(100,)\n",
    "    if activation==None:\n",
    "        activation=\"relu\"\n",
    "    if solver==None:\n",
    "        solver=\"adam\"\n",
    "    if alpha==None:\n",
    "        alpha=0.0001\n",
    "    clf = sklearn.neural_network.MLPClassifier(hidden_layer_sizes=hls, activation=activation, solver=solver, alpha=alpha)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Fold CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_train_test_using_kfold(k, X, y):\n",
    "    trainset, testset = [], []\n",
    "    kf = sklearn.model_selection.KFold(n_splits=k, shuffle=True)\n",
    "    kf.get_n_splits(X)\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    print(kf)\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train.append(X[train_index])\n",
    "        y_train.append(y[train_index])\n",
    "        X_test.append(X[test_index])\n",
    "        y_test.append(y[test_index])\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_knn_csv(infile):\n",
    "    # Skip the header\n",
    "    header = infile.readline().rstrip().split(',')\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in infile:\n",
    "        line = line.rstrip().split(',')\n",
    "        # Skip the ID\n",
    "        X.append([float(x) for x in line[1:-1]])\n",
    "        y.append(int(line[-1]))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def perform_knn(infile, k_fold):\n",
    "    # Prepare X and y from the input txt file\n",
    "    f = open(infile, 'r+')\n",
    "    X, y = read_knn_csv(f)\n",
    "\n",
    "    # Get trainsets and testsets using K-Fold\n",
    "    X_train, y_train, X_test, y_test = prepare_train_test_using_kfold(k_fold, X, y)\n",
    "\n",
    "    max_n = 19\n",
    "    weights_tuple = (\"uniform\", \"distance\")\n",
    "\n",
    "    print('-'*60)\n",
    "    print(\"k nearest algorithm\")\n",
    "    \n",
    "    for weights in weights_tuple:\n",
    "        for n in range(1, max_n, 2):\n",
    "            accuracy_list = np.zeros(k_fold)\n",
    "            for i in range(k_fold):\n",
    "                pred = k_nearest_neighbor(X_train[i], y_train[i], X_test[i], n, weights)\n",
    "                accuracy = sklearn.metrics.accuracy_score(y_test[i], pred)\n",
    "                accuracy_list[i] = accuracy\n",
    "            print(\"{0:.3f},n={1},weights={2},kNN\".format(accuracy_list.mean(),n,weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=True)\n",
      "------------------------------------------------------------\n",
      "k nearest algorithm\n",
      "0.733,n=1,weights=uniform,kNN\n",
      "0.747,n=3,weights=uniform,kNN\n",
      "0.746,n=5,weights=uniform,kNN\n",
      "0.745,n=7,weights=uniform,kNN\n",
      "0.739,n=9,weights=uniform,kNN\n",
      "0.735,n=11,weights=uniform,kNN\n",
      "0.728,n=13,weights=uniform,kNN\n",
      "0.724,n=15,weights=uniform,kNN\n",
      "0.724,n=17,weights=uniform,kNN\n",
      "0.733,n=1,weights=distance,kNN\n",
      "0.747,n=3,weights=distance,kNN\n",
      "0.746,n=5,weights=distance,kNN\n",
      "0.745,n=7,weights=distance,kNN\n",
      "0.739,n=9,weights=distance,kNN\n",
      "0.735,n=11,weights=distance,kNN\n",
      "0.728,n=13,weights=distance,kNN\n",
      "0.724,n=15,weights=distance,kNN\n",
      "0.724,n=17,weights=distance,kNN\n"
     ]
    }
   ],
   "source": [
    "perform_knn(\"data_processed_angle_removed.csv\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=True)\n",
      "------------------------------------------------------------\n",
      "k nearest algorithm\n",
      "0.749,n=1,weights=uniform,kNN\n",
      "0.758,n=3,weights=uniform,kNN\n",
      "0.751,n=5,weights=uniform,kNN\n",
      "0.745,n=7,weights=uniform,kNN\n",
      "0.750,n=9,weights=uniform,kNN\n",
      "0.742,n=11,weights=uniform,kNN\n",
      "0.731,n=13,weights=uniform,kNN\n",
      "0.727,n=15,weights=uniform,kNN\n",
      "0.727,n=17,weights=uniform,kNN\n",
      "0.749,n=1,weights=distance,kNN\n",
      "0.758,n=3,weights=distance,kNN\n",
      "0.751,n=5,weights=distance,kNN\n",
      "0.745,n=7,weights=distance,kNN\n",
      "0.750,n=9,weights=distance,kNN\n",
      "0.742,n=11,weights=distance,kNN\n",
      "0.731,n=13,weights=distance,kNN\n",
      "0.727,n=15,weights=distance,kNN\n",
      "0.727,n=17,weights=distance,kNN\n"
     ]
    }
   ],
   "source": [
    "perform_knn(\"data_processed_rows_eliminated.csv\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=True)\n",
      "------------------------------------------------------------\n",
      "k nearest algorithm\n",
      "0.701,n=1,weights=uniform,kNN\n",
      "0.707,n=3,weights=uniform,kNN\n",
      "0.697,n=5,weights=uniform,kNN\n",
      "0.703,n=7,weights=uniform,kNN\n",
      "0.684,n=9,weights=uniform,kNN\n",
      "0.689,n=11,weights=uniform,kNN\n",
      "0.686,n=13,weights=uniform,kNN\n",
      "0.684,n=15,weights=uniform,kNN\n",
      "0.683,n=17,weights=uniform,kNN\n",
      "0.701,n=1,weights=distance,kNN\n",
      "0.707,n=3,weights=distance,kNN\n",
      "0.697,n=5,weights=distance,kNN\n",
      "0.703,n=7,weights=distance,kNN\n",
      "0.684,n=9,weights=distance,kNN\n",
      "0.689,n=11,weights=distance,kNN\n",
      "0.686,n=13,weights=distance,kNN\n",
      "0.684,n=15,weights=distance,kNN\n",
      "0.683,n=17,weights=distance,kNN\n"
     ]
    }
   ],
   "source": [
    "perform_knn(\"data_processed_bands_combined.csv\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_rf_csv(infile):\n",
    "    # Skip the header\n",
    "    header = infile.readline().rstrip().split(',')\n",
    "    X = []\n",
    "    y = []\n",
    "    for line in infile:\n",
    "        line = line.rstrip().split(',')\n",
    "        # Skip the ID\n",
    "        X.append([float(x) for x in line[1:-1]])\n",
    "        y.append(int(line[-1]))\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def perform_random_forest(infile, k_fold):\n",
    "    f = open(infile, 'r+')\n",
    "    \n",
    "    # Prepare X and y from the input txt file\n",
    "    X, y = read_rf_csv(f)\n",
    "\n",
    "    # Get trainsets and testsets using K-Fold\n",
    "    X_train, y_train, X_test, y_test = prepare_train_test_using_kfold(k_fold, X, y)\n",
    "\n",
    "    # number of trees: 4, 8, ... , 4096\n",
    "    # minss: 2, 4, ... , 32 \n",
    "    criterion_tuple = (\"gini\", \"entropy\")\n",
    "    n_list = np.power(2, np.arange(2, 13))\n",
    "    minss_list = np.power(2, np.arange(1, 6))\n",
    "    \n",
    "    # Random Forest\n",
    "    print('-'*60)\n",
    "    print(\"\\nRandom Forest\")\n",
    "    for criterion in criterion_tuple:\n",
    "        for n in n_list:\n",
    "            for minss in minss_list:\n",
    "                accuracy_list = np.zeros(k_fold)\n",
    "                for i in range(k_fold):\n",
    "                    pred = random_forest(X_train[i], y_train[i], X_test[i], n, criterion, minss)\n",
    "                    accuracy = sklearn.metrics.accuracy_score(y_test[i], pred)\n",
    "                    accuracy_list[i] = accuracy\n",
    "                print(\"{0:.3f},criterion={1},n={2},minss={3},RandomForest\".format(accuracy_list.mean(),criterion,n,minss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=True)\n",
      "------------------------------------------------------------\n",
      "\n",
      "Random Forest\n",
      "0.652,criterion=gini,n=4,minss=2,RandomForest\n",
      "0.628,criterion=gini,n=4,minss=4,RandomForest\n",
      "0.671,criterion=gini,n=4,minss=8,RandomForest\n",
      "0.650,criterion=gini,n=4,minss=16,RandomForest\n",
      "0.668,criterion=gini,n=4,minss=32,RandomForest\n",
      "0.683,criterion=gini,n=8,minss=2,RandomForest\n",
      "0.680,criterion=gini,n=8,minss=4,RandomForest\n",
      "0.700,criterion=gini,n=8,minss=8,RandomForest\n",
      "0.676,criterion=gini,n=8,minss=16,RandomForest\n",
      "0.695,criterion=gini,n=8,minss=32,RandomForest\n",
      "0.713,criterion=gini,n=16,minss=2,RandomForest\n",
      "0.709,criterion=gini,n=16,minss=4,RandomForest\n",
      "0.708,criterion=gini,n=16,minss=8,RandomForest\n",
      "0.724,criterion=gini,n=16,minss=16,RandomForest\n",
      "0.718,criterion=gini,n=16,minss=32,RandomForest\n",
      "0.721,criterion=gini,n=32,minss=2,RandomForest\n",
      "0.733,criterion=gini,n=32,minss=4,RandomForest\n",
      "0.724,criterion=gini,n=32,minss=8,RandomForest\n",
      "0.721,criterion=gini,n=32,minss=16,RandomForest\n",
      "0.725,criterion=gini,n=32,minss=32,RandomForest\n",
      "0.738,criterion=gini,n=64,minss=2,RandomForest\n",
      "0.744,criterion=gini,n=64,minss=4,RandomForest\n",
      "0.731,criterion=gini,n=64,minss=8,RandomForest\n",
      "0.734,criterion=gini,n=64,minss=16,RandomForest\n",
      "0.718,criterion=gini,n=64,minss=32,RandomForest\n",
      "0.743,criterion=gini,n=128,minss=2,RandomForest\n",
      "0.734,criterion=gini,n=128,minss=4,RandomForest\n",
      "0.747,criterion=gini,n=128,minss=8,RandomForest\n",
      "0.732,criterion=gini,n=128,minss=16,RandomForest\n",
      "0.740,criterion=gini,n=128,minss=32,RandomForest\n",
      "0.737,criterion=gini,n=256,minss=2,RandomForest\n",
      "0.740,criterion=gini,n=256,minss=4,RandomForest\n",
      "0.743,criterion=gini,n=256,minss=8,RandomForest\n",
      "0.735,criterion=gini,n=256,minss=16,RandomForest\n",
      "0.738,criterion=gini,n=256,minss=32,RandomForest\n",
      "0.743,criterion=gini,n=512,minss=2,RandomForest\n",
      "0.746,criterion=gini,n=512,minss=4,RandomForest\n",
      "0.749,criterion=gini,n=512,minss=8,RandomForest\n",
      "0.743,criterion=gini,n=512,minss=16,RandomForest\n",
      "0.739,criterion=gini,n=512,minss=32,RandomForest\n",
      "0.747,criterion=gini,n=1024,minss=2,RandomForest\n",
      "0.749,criterion=gini,n=1024,minss=4,RandomForest\n",
      "0.749,criterion=gini,n=1024,minss=8,RandomForest\n",
      "0.744,criterion=gini,n=1024,minss=16,RandomForest\n",
      "0.738,criterion=gini,n=1024,minss=32,RandomForest\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-057298591257>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mperform_random_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data_processed_angle_removed.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-32-39a58cc7651e>\u001b[0m in \u001b[0;36mperform_random_forest\u001b[1;34m(infile, k_fold)\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0maccuracy_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mk_fold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m                     \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_forest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mminss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m                     \u001b[0maccuracy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m                     \u001b[0maccuracy_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-6cb29acdfd01>\u001b[0m in \u001b[0;36mrandom_forest\u001b[1;34m(X_train, y_train, X_test, n, criterion, minss)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mminss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mminss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    325\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 327\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    118\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    788\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 790\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    791\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perform_random_forest('data_processed_angle_removed.csv', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.652,\n",
    "0.628,\n",
    "0.671,\n",
    "0.650,\n",
    "0.668,\n",
    "0.683,\n",
    "0.680,\n",
    "0.700,\n",
    "0.676,\n",
    "0.695,\n",
    "0.713,\n",
    "0.709,\n",
    "0.708,\n",
    "0.724,\n",
    "0.718,\n",
    "0.721,\n",
    "0.733,\n",
    "0.724,\n",
    "0.721,\n",
    "0.725,\n",
    "0.738,\n",
    "0.744,\n",
    "0.731,\n",
    "0.734,criterion=gini,n=64,minss=16,RandomForest\n",
    "0.718,criterion=gini,n=64,minss=32,RandomForest\n",
    "0.743,criterion=gini,n=128,minss=2,RandomForest\n",
    "0.734,criterion=gini,n=128,minss=4,RandomForest\n",
    "0.747,criterion=gini,n=128,minss=8,RandomForest\n",
    "0.732,criterion=gini,n=128,minss=16,RandomForest\n",
    "0.740,criterion=gini,n=128,minss=32,RandomForest\n",
    "0.737,criterion=gini,n=256,minss=2,RandomForest\n",
    "0.740,criterion=gini,n=256,minss=4,RandomForest\n",
    "0.743,criterion=gini,n=256,minss=8,RandomForest\n",
    "0.735,criterion=gini,n=256,minss=16,RandomForest\n",
    "0.738,criterion=gini,n=256,minss=32,RandomForest\n",
    "0.743,criterion=gini,n=512,minss=2,RandomForest\n",
    "0.746,criterion=gini,n=512,minss=4,RandomForest\n",
    "0.749,criterion=gini,n=512,minss=8,RandomForest\n",
    "0.743,criterion=gini,n=512,minss=16,RandomForest\n",
    "0.739,criterion=gini,n=512,minss=32,RandomForest\n",
    "0.747,criterion=gini,n=1024,minss=2,RandomForest\n",
    "0.749,criterion=gini,n=1024,minss=4,RandomForest\n",
    "0.749,criterion=gini,n=1024,minss=8,RandomForest\n",
    "0.744,criterion=gini,n=1024,minss=16,RandomForest\n",
    "0.738,criterion=gini,n=1024,minss=32,RandomFore"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
